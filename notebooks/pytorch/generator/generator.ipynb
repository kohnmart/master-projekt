{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Diffusion Pipeline (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/img2img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../..')))\n",
    "\n",
    "from config.path import get_stable_input_path, get_stable_output_path\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "import datetime\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "import random\n",
    "\n",
    "\n",
    "device = \"cuda\" # this works gpu only\n",
    "model_id_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "PATH_TO_STABLE_INPUT = get_stable_input_path()\n",
    "PATH_TO_STABLE_OUTPUT = get_stable_output_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cloth type\n",
    "clothType = 'mixed_'\n",
    "\n",
    "prompts = [\n",
    "        f'generated two clothes'\n",
    "        #f'Transform this {clothType}, add new color and material, add crumpled and wrinkled up, add white seamless background'\n",
    "        \n",
    "        # f'{clothType} in random layout',\n",
    "        # f'single {clothType} with pockets laying on white plain background'\n",
    "        # f'single {clothType} with zipper on white plain background',\n",
    "        # f'single {clothType} with knobs on white plain background'\n",
    "        # f'single {clothType} with print on white plain background'\n",
    "        # f'make this {clothType} look from the backside',\n",
    "]\n",
    "\n",
    "negative_prompt = ['hands, face, hair, eyes, human, woman, men, person, skin, shadow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m init_image \u001b[39m=\u001b[39m init_image\u001b[39m.\u001b[39mresize((\u001b[39m500\u001b[39m, \u001b[39m500\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[0;32m----> 7\u001b[0m     images \u001b[39m=\u001b[39m pipe(prompt\u001b[39m=\u001b[39;49mprompt, negative_prompt\u001b[39m=\u001b[39;49mnegative_prompt[\u001b[39m0\u001b[39;49m], image\u001b[39m=\u001b[39;49minit_image, strength\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, guidance_scale\u001b[39m=\u001b[39;49m\u001b[39m7\u001b[39;49m)\u001b[39m.\u001b[39mimages\n\u001b[1;32m      8\u001b[0m     current_timestamp \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[1;32m      9\u001b[0m     formatted_timestamp \u001b[39m=\u001b[39m current_timestamp\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39mH\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m)  \u001b[39m# Format the timestamp as a string\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion_img2img.py:766\u001b[0m, in \u001b[0;36mStableDiffusionImg2ImgPipeline.__call__\u001b[0;34m(self, prompt, image, strength, num_inference_steps, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, prompt_embeds, negative_prompt_embeds, output_type, return_dict, callback, callback_steps, cross_attention_kwargs)\u001b[0m\n\u001b[1;32m    763\u001b[0m latent_model_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mscale_model_input(latent_model_input, t)\n\u001b[1;32m    765\u001b[0m \u001b[39m# predict the noise residual\u001b[39;00m\n\u001b[0;32m--> 766\u001b[0m noise_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munet(\n\u001b[1;32m    767\u001b[0m     latent_model_input,\n\u001b[1;32m    768\u001b[0m     t,\n\u001b[1;32m    769\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mprompt_embeds,\n\u001b[1;32m    770\u001b[0m     cross_attention_kwargs\u001b[39m=\u001b[39;49mcross_attention_kwargs,\n\u001b[1;32m    771\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    772\u001b[0m )[\u001b[39m0\u001b[39m]\n\u001b[1;32m    774\u001b[0m \u001b[39m# perform guidance\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[39mif\u001b[39;00m do_classifier_free_guidance:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/diffusers/models/unet_2d_condition.py:956\u001b[0m, in \u001b[0;36mUNet2DConditionModel.forward\u001b[0;34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[1;32m    953\u001b[0m     upsample_size \u001b[39m=\u001b[39m down_block_res_samples[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m:]\n\u001b[1;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(upsample_block, \u001b[39m\"\u001b[39m\u001b[39mhas_cross_attention\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m upsample_block\u001b[39m.\u001b[39mhas_cross_attention:\n\u001b[0;32m--> 956\u001b[0m     sample \u001b[39m=\u001b[39m upsample_block(\n\u001b[1;32m    957\u001b[0m         hidden_states\u001b[39m=\u001b[39;49msample,\n\u001b[1;32m    958\u001b[0m         temb\u001b[39m=\u001b[39;49memb,\n\u001b[1;32m    959\u001b[0m         res_hidden_states_tuple\u001b[39m=\u001b[39;49mres_samples,\n\u001b[1;32m    960\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    961\u001b[0m         cross_attention_kwargs\u001b[39m=\u001b[39;49mcross_attention_kwargs,\n\u001b[1;32m    962\u001b[0m         upsample_size\u001b[39m=\u001b[39;49mupsample_size,\n\u001b[1;32m    963\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    964\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    965\u001b[0m     )\n\u001b[1;32m    966\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    967\u001b[0m     sample \u001b[39m=\u001b[39m upsample_block(\n\u001b[1;32m    968\u001b[0m         hidden_states\u001b[39m=\u001b[39msample, temb\u001b[39m=\u001b[39memb, res_hidden_states_tuple\u001b[39m=\u001b[39mres_samples, upsample_size\u001b[39m=\u001b[39mupsample_size\n\u001b[1;32m    969\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/diffusers/models/unet_2d_blocks.py:2127\u001b[0m, in \u001b[0;36mCrossAttnUpBlock2D.forward\u001b[0;34m(self, hidden_states, res_hidden_states_tuple, temb, encoder_hidden_states, cross_attention_kwargs, upsample_size, attention_mask, encoder_attention_mask)\u001b[0m\n\u001b[1;32m   2125\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2126\u001b[0m         hidden_states \u001b[39m=\u001b[39m resnet(hidden_states, temb)\n\u001b[0;32m-> 2127\u001b[0m         hidden_states \u001b[39m=\u001b[39m attn(\n\u001b[1;32m   2128\u001b[0m             hidden_states,\n\u001b[1;32m   2129\u001b[0m             encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   2130\u001b[0m             cross_attention_kwargs\u001b[39m=\u001b[39;49mcross_attention_kwargs,\n\u001b[1;32m   2131\u001b[0m             attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   2132\u001b[0m             encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m   2133\u001b[0m             return_dict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   2134\u001b[0m         )[\u001b[39m0\u001b[39m]\n\u001b[1;32m   2136\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupsamplers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2137\u001b[0m     \u001b[39mfor\u001b[39;00m upsampler \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupsamplers:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/diffusers/models/transformer_2d.py:291\u001b[0m, in \u001b[0;36mTransformer2DModel.forward\u001b[0;34m(self, hidden_states, encoder_hidden_states, timestep, class_labels, cross_attention_kwargs, attention_mask, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[39m# 2. Blocks\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_blocks:\n\u001b[0;32m--> 291\u001b[0m     hidden_states \u001b[39m=\u001b[39m block(\n\u001b[1;32m    292\u001b[0m         hidden_states,\n\u001b[1;32m    293\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    294\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    295\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    296\u001b[0m         timestep\u001b[39m=\u001b[39;49mtimestep,\n\u001b[1;32m    297\u001b[0m         cross_attention_kwargs\u001b[39m=\u001b[39;49mcross_attention_kwargs,\n\u001b[1;32m    298\u001b[0m         class_labels\u001b[39m=\u001b[39;49mclass_labels,\n\u001b[1;32m    299\u001b[0m     )\n\u001b[1;32m    301\u001b[0m \u001b[39m# 3. Output\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_input_continuous:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/diffusers/models/attention.py:154\u001b[0m, in \u001b[0;36mBasicTransformerBlock.forward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, timestep, cross_attention_kwargs, class_labels)\u001b[0m\n\u001b[1;32m    150\u001b[0m     norm_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(hidden_states)\n\u001b[1;32m    152\u001b[0m cross_attention_kwargs \u001b[39m=\u001b[39m cross_attention_kwargs \u001b[39mif\u001b[39;00m cross_attention_kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m--> 154\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn1(\n\u001b[1;32m    155\u001b[0m     norm_hidden_states,\n\u001b[1;32m    156\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49monly_cross_attention \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    157\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    158\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcross_attention_kwargs,\n\u001b[1;32m    159\u001b[0m )\n\u001b[1;32m    160\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_ada_layer_norm_zero:\n\u001b[1;32m    161\u001b[0m     attn_output \u001b[39m=\u001b[39m gate_msa\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m attn_output\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/diffusers/models/attention_processor.py:321\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, hidden_states, encoder_hidden_states, attention_mask, **cross_attention_kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states, encoder_hidden_states\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, attention_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcross_attention_kwargs):\n\u001b[1;32m    318\u001b[0m     \u001b[39m# The `Attention` class can call different attention processors / attention functions\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39m# here we simply pass along all tensors to the selected processor class\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[39m# For standard processors that are defined here, `**cross_attention_kwargs` is empty\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocessor(\n\u001b[1;32m    322\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    323\u001b[0m         hidden_states,\n\u001b[1;32m    324\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    325\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    326\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcross_attention_kwargs,\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/diffusers/models/attention_processor.py:1129\u001b[0m, in \u001b[0;36mAttnProcessor2_0.__call__\u001b[0;34m(self, attn, hidden_states, encoder_hidden_states, attention_mask, temb)\u001b[0m\n\u001b[1;32m   1125\u001b[0m value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mview(batch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, attn\u001b[39m.\u001b[39mheads, head_dim)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m   1127\u001b[0m \u001b[39m# the output of sdp = (batch, num_heads, seq_len, head_dim)\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39m# TODO: add support for attn.scale when we move to Torch 2.1\u001b[39;00m\n\u001b[0;32m-> 1129\u001b[0m hidden_states \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mscaled_dot_product_attention(\n\u001b[1;32m   1130\u001b[0m     query, key, value, attn_mask\u001b[39m=\u001b[39;49mattention_mask, dropout_p\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m, is_causal\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m   1131\u001b[0m )\n\u001b[1;32m   1133\u001b[0m hidden_states \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mreshape(batch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, attn\u001b[39m.\u001b[39mheads \u001b[39m*\u001b[39m head_dim)\n\u001b[1;32m   1134\u001b[0m hidden_states \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39mto(query\u001b[39m.\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "for raw_sample in os.listdir(PATH_TO_STABLE_INPUT):\n",
    "    imgPath = os.path.join(PATH_TO_STABLE_INPUT, raw_sample)\n",
    "    init_image = Image.open(imgPath).convert(\"RGB\")\n",
    "    init_image = init_image.resize((500, 500))\n",
    "\n",
    "    for prompt in prompts:\n",
    "        images = pipe(prompt=prompt, negative_prompt=negative_prompt[0], image=init_image, strength=1, guidance_scale=7).images\n",
    "        current_timestamp = datetime.datetime.now()\n",
    "        formatted_timestamp = current_timestamp.strftime(\"%Y%m%d%H%M%S\")  # Format the timestamp as a string\n",
    "    \n",
    "        name = clothType + formatted_timestamp + \"_0.png\"\n",
    "        images[0].save(os.path.join(PATH_TO_STABLE_OUTPUT, name))\n",
    "\n",
    "        # generations\n",
    "        for i in range(0, 2):\n",
    "                mirr_image = images[0].transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                # Mirror the image horizontally (left-to-right)\n",
    "                image_var = pipe(prompt=prompt, \n",
    "                              negative_prompt=negative_prompt[0], \n",
    "                              image=mirr_image, \n",
    "                              strength=0.7, \n",
    "                              guidance_scale=(random.randint(5,7))\n",
    "                              ).images\n",
    "                name = clothType + formatted_timestamp + \"_\" + str(i+1) + \".png\"\n",
    "                image_var[0].save(os.path.join(PATH_TO_STABLE_OUTPUT, name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
