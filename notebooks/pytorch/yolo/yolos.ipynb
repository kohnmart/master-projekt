{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOS PLAYGROUND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: white;\">\n",
    "Explanation: This notebook serves as a testing environment to debug YOLOS parameters, detection and confidence on given samples.\n",
    "</span>\n",
    "\n",
    "\n",
    "https://huggingface.co/hustvl/yolos-tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../..')))\n",
    "\n",
    "from config.path import get_training_data_path, get_checkpoint_path, DATASET_PATH_TYPE\n",
    "\n",
    "from transformers import YolosImageProcessor, YolosForObjectDetection\n",
    "from PIL import Image\n",
    "import torch\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOAD TINY YOLOS MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YolosForObjectDetection.from_pretrained('hustvl/yolos-tiny')\n",
    "image_processor = YolosImageProcessor.from_pretrained('hustvl/yolos-tiny')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA LOADING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path = get_training_data_path('production', 'band')\n",
    "fullpath = os.path.join(relative_path, 'frame_38__.jpg')\n",
    "image = Image.open(fullpath)\n",
    "\n",
    "image = np.array(image)\n",
    "\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOLOS PROCESSING AND PLOTTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image):\n",
    "\n",
    "    detected = False\n",
    "    cropped_image = []\n",
    "\n",
    "    inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    bboxes = outputs.pred_boxes\n",
    "\n",
    "    image_np = np.array(image)  # Convert the image to a NumPy array once\n",
    "    height, width, _ = image_np.shape\n",
    "    target_sizes = torch.tensor([[height, width]]) \n",
    "\n",
    "    results = image_processor.post_process_object_detection(outputs, threshold=0.2, target_sizes=target_sizes)[0]\n",
    "    # Iterate over detected objects and process bounding boxes\n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        box = box.detach().numpy()  # Detach tensor and convert to numpy array\n",
    "        x_min, y_min, x_max, y_max = map(int, box)\n",
    "        # Ensure bounding box is within image dimensions\n",
    "        x_min = max(0, x_min)\n",
    "        y_min = max(0, y_min)\n",
    "        x_max = min(width, x_max)\n",
    "        y_max = min(height, y_max)\n",
    "        cropped_image = image_np[y_min:y_max, x_min:x_max]\n",
    "        x, y = cropped_image.shape[:2]\n",
    "        if 100 <= x_min <= 130 and (x * y >= 60000):\n",
    "            # Display the cropped image\n",
    "            detected = True\n",
    "            found_objects = cropped_image\n",
    "            fig, ax_cropped = plt.subplots(1, figsize=(4, 4))  # Use reasonable size for the cropped image\n",
    "            ax_cropped.imshow(found_objects)\n",
    "            ax_cropped.set_title(f'Label: {model.config.id2label[label.item()]}, Confidence: {score.item():0.2f}')\n",
    "            plt.show()\n",
    "\n",
    "process(image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
