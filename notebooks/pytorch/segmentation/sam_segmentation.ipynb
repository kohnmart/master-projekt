{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEGMENT ANYTHING MODEL (META)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: white;\">\n",
    "Explanation: This is comprehensive notebook environment to work the SAM Segmentation Model, extracting masks and evualuating on the overlaps blueprints.\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/facebook/sam-vit-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../../..')))\n",
    "\n",
    "from config.path import get_training_data_path, get_checkpoint_path, get_all_files_from_folder, DATASET_PATH_TYPE\n",
    "from src.utils.augmentation import erase_generator\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "from notebooks.pytorch.segmentation.helper.segment_anything import load_images\n",
    "import cv2\n",
    "import supervision as sv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTALLS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "# %pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision\n",
    "# !wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -P ./weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = get_checkpoint_path(\"sam_vit_h_4b8939.pth\")\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_TYPE = \"vit_h\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/facebookresearch/segment-anything/blob/main/segment_anything/automatic_mask_generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=5,\n",
    "    pred_iou_thresh=0.9,\n",
    "    stability_score_thresh=0.9,\n",
    "    crop_n_layers=1,\n",
    "    crop_n_points_downscale_factor=0.5,\n",
    "    min_mask_region_area=100,  # Requires open-cv to run post-processing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GET DATA PATH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path = get_training_data_path('setup-v2', 'pant-stage-1')\n",
    "print(relative_path)\n",
    "file_names = get_all_files_from_folder(relative_path)[:20]\n",
    "\n",
    "for file_name in file_names:\n",
    "    fullpath = os.path.join(relative_path, file_name)\n",
    "    n_image, blurred_image = process_image(fullpath)\n",
    "    cleaned_masks = generate_masks(blurred_image)\n",
    "    \n",
    "    if not cleaned_masks:\n",
    "        continue\n",
    "    \n",
    "    final_annotated_image = annotate_images(n_image, blurred_image, cleaned_masks)\n",
    "    masks_cleaned = clean_masks(cleaned_masks)\n",
    "    \n",
    "    if masks_cleaned:\n",
    "        crop_and_save_mask(masks_cleaned, n_image, file_name.split('.')[0])\n",
    "    \n",
    "    plot_images([n_image, final_annotated_image], ['source image', 'segmented image'], grid_size=(1, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GET BLUEPRINT MASKS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_all_files_from_folder('./blueprints')\n",
    "blueprint_masks = []\n",
    "for file in files:\n",
    "    fullpath = './blueprints/' + file\n",
    "    mask = cv2.imread(fullpath, cv2.IMREAD_GRAYSCALE)\n",
    "    _, mask = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)\n",
    "    blueprint_masks.append(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overlap(mask1, mask2):\n",
    "    # Compute the overlapping area between two binary masks\n",
    "    overlap = np.sum((mask1 == 255) & (mask2 == 255))\n",
    "    return overlap\n",
    "\n",
    "def find_best_rotation(input_mask, blueprint_mask, angle_step=1):\n",
    "    best_angle = 0\n",
    "    max_overlap = 0\n",
    "    \n",
    "    for angle in range(0, 360, angle_step):\n",
    "        # Rotate the input mask\n",
    "        rotated_mask = rotate_image(input_mask, angle)\n",
    "        \n",
    "        # Compute the overlap with the blueprint mask\n",
    "        overlap = compute_overlap(rotated_mask, blueprint_mask)\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_angle = angle\n",
    "    \n",
    "    #print(f\"Best mask: {blueprint_mask[0]}\")\n",
    "    return [max_overlap, best_angle]\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w / 2, h / 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_NEAREST)\n",
    "    return rotated\n",
    "\n",
    "\n",
    "\n",
    "def plot_before_after_rotations(rotated_masks, original_image, num_rows=18):\n",
    "    # fig, axs = plt.subplots(num_rows, 4, figsize=(16, num_rows * 3))\n",
    "    # plt.subplots_adjust(hspace=0.0, wspace=0.0)  # Reduce padding between subplots\n",
    "\n",
    "    # for i in range(num_rows):\n",
    "    #     line_ax = fig.add_subplot(num_rows, 1, i + 1, frame_on=False)\n",
    "    #     line_ax.plot([0.5, 0.5], [0, 1], transform=fig.transFigure, color='red', linestyle='--')\n",
    "    #     line_ax.axis('off')  # Turn off the axis\n",
    "\n",
    "    random_angle = random.uniform(0, 360)\n",
    "    tester = rotate_image(original_image, random_angle)\n",
    "    angles = []\n",
    "    for blueprint_mask in blueprint_masks:\n",
    "        blueprint_mask = cv2.resize(blueprint_mask, (256, 256))\n",
    "        best_angle = find_best_rotation(tester, blueprint_mask)\n",
    "        angles.append(best_angle)\n",
    "    best_angle_final = np.max(angles, axis=0)[1]\n",
    "\n",
    "    print(best_angle_final)\n",
    "    #aligned_image = rotate_image(tester, best_angle_final)\n",
    "        \n",
    "        # row = i // 2\n",
    "        # col = (i % 2) * 2\n",
    "        \n",
    "        # axs[row, col].imshow(tester, cmap='gray')\n",
    "        # axs[row, col].set_title(f'Before Rotation {i*10}째')\n",
    "        # axs[row, col].axis('off')\n",
    "\n",
    "        # axs[row, col + 1].imshow(aligned_image, cmap='gray')\n",
    "        # axs[row, col + 1].set_title(f'After Best Rotation {best_angle_final}째')\n",
    "        # axs[row, col + 1].axis('off')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.savefig(f'./plots/{file_name}')\n",
    "\n",
    "\n",
    "def get_best_angle_overlaps(image):\n",
    "    random_angle = random.uniform(0, 360)\n",
    "    tester = rotate_image(image, random_angle)\n",
    "    angles = []\n",
    "    for blueprint_mask in blueprint_masks:\n",
    "        blueprint_mask = cv2.resize(blueprint_mask[1], (256, 256))\n",
    "        best_angle = find_best_rotation(tester, blueprint_mask)\n",
    "        angles.append(best_angle)\n",
    "    best_angle_final = np.max(angles, axis=0)[1]\n",
    "    return best_angle_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_training_data_path('masks', 'shirt')\n",
    "files = get_all_files_from_folder(path)\n",
    "print(len(files))\n",
    "res = []\n",
    "\n",
    "for file in files:\n",
    "    fullpath = os.path.join(path, file)\n",
    "    random_angle = random.uniform(0, 360)\n",
    "    img = cv2.imread(fullpath)\n",
    "    alpha_channel = img[:, :, 2]\n",
    "    img = (alpha_channel > 0).astype(np.uint8) * 255\n",
    "    corrected_angle = get_best_angle_overlaps(img)\n",
    "    res.append([random_angle, corrected_angle])\n",
    "\n",
    "# Convert to numpy array for easier manipulation\n",
    "res = np.array(res)\n",
    "random_angles = res[:, 0]\n",
    "corrected_angles = res[:, 1]\n",
    "\n",
    "# Compute absolute errors\n",
    "errors = np.abs(random_angles - corrected_angles)\n",
    "errors = np.minimum(errors, 360 - errors)  # Account for circular nature of angles\n",
    "\n",
    "# Calculate summary statistics\n",
    "mean_error = np.mean(errors)\n",
    "std_error = np.std(errors)\n",
    "\n",
    "# Print summary statistics\n",
    "print(f'Mean Absolute Error: {mean_error:.2f}째')\n",
    "print(f'Standard Deviation of Error: {std_error:.2f}째')\n",
    "\n",
    "# Assign unique colors to each pair\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(random_angles)))\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Scatter plot of random angles vs. corrected angles with pair-wise colors and lines\n",
    "for i in range(len(random_angles)):\n",
    "    ax[0].scatter(random_angles[i], corrected_angles[i], color=colors[i], alpha=0.75)\n",
    "    ax[0].plot([random_angles[i], random_angles[i]], [random_angles[i], corrected_angles[i]], color=colors[i], alpha=0.5, linestyle='-')\n",
    "\n",
    "ax[0].plot([0, 360], [0, 360], color='red', linestyle='--')  # Perfect correlation line\n",
    "ax[0].set_xlabel('Random Angles (Ground Truth)')\n",
    "ax[0].set_ylabel('Corrected Angles')\n",
    "ax[0].set_title('Random Angles vs. Corrected Angles')\n",
    "ax[0].set_xlim([0, 360])\n",
    "ax[0].set_ylim([0, 360])\n",
    "\n",
    "# Histogram of errors\n",
    "ax[1].hist(errors, bins=30, alpha=0.75, color='blue')\n",
    "ax[1].set_xlabel('Absolute Error (째)')\n",
    "ax[1].set_ylabel('Frequency')\n",
    "ax[1].set_title('Distribution of Absolute Errors')\n",
    "\n",
    "plt.suptitle('Evaluation of Angle Correction Accuracy Shirt')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
