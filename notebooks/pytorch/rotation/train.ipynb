{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# fastAI\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.tracker import Recorder\n",
    "from fastai.interpret import ClassificationInterpretation\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# If using the current directory\n",
    "current_dir = Path.cwd()\n",
    "\n",
    "# If you need to navigate relative to the current directory\n",
    "project_root = current_dir.parent.parent.parent\n",
    "relative_path = project_root / 'dataset' / 'rotation' / 'train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_transforms_list = aug_transforms(size=224)\n",
    "\n",
    "# Define data loading and preprocessing pipeline using DataBlock\n",
    "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                get_items=get_image_files,\n",
    "                splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "                get_y=parent_label,\n",
    "                item_tfms=Resize(224), \n",
    "                batch_tfms=aug_transforms_list)\n",
    "\n",
    "dls = dblock.dataloaders(relative_path, bs=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a learner with ResNet18 architecture\n",
    "epochs = 50\n",
    "\n",
    "learn = vision_learner(dls, resnet50, metrics=accuracy, ps=0, wd=0)\n",
    "\n",
    "# Attach Recorder callback to track metrics during training\n",
    "recorder = Recorder()\n",
    "learn.add_cb(recorder)\n",
    "\n",
    "# Fine-tune the model for 2 epochs with a base learning rate of 3e-3\n",
    "learn.fine_tune(epochs, base_lr=3e-3)\n",
    "\n",
    "path = os.path.join('./', f\"test.pkl\")\n",
    "\n",
    "learn.export(path)\n",
    "# Plot the training and validation losses\n",
    "\n",
    "recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import load_learner\n",
    "\n",
    "# Load the trained model\n",
    "path = './test.pkl'\n",
    "learn = load_learner(path)\n",
    "\n",
    "# Load an image\n",
    "img_path = 'test.jpg'\n",
    "img = Image.open(img_path)\n",
    "img = img.rotate(-260)\n",
    "# If you used any specific item transforms during training, apply them here\n",
    "img = img.resize((224, 224))  # Example resize, adjust according to your training setup\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "# Make a prediction\n",
    "pred, pred_idx, probs = learn.predict(img)\n",
    "\n",
    "print(f\"Prediction: {pred}\")\n",
    "print(f\"Prediction Index: {pred_idx}\")\n",
    "print(f\"Probabilities: {probs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import timm\n",
    "\n",
    "def timm_vision_transformer(name, pretrained=True, **kwargs):\n",
    "    \"\"\" Create a vision transformer model from timm library \"\"\"\n",
    "    return timm.create_model(name, pretrained=pretrained, **kwargs)\n",
    "\n",
    "# Example of using a Vision Transformer model 'vit_base_patch16_224'\n",
    "vit_model = timm_vision_transformer('vit_base_patch16_224', pretrained=True)\n",
    "\n",
    "# You can now integrate this model into a fastai Learner\n",
    "dls = ImageDataLoaders.from_folder(relative_path, valid_pct=0.2, item_tfms=Resize(224), batch_tfms=Normalize.from_stats(*imagenet_stats))\n",
    "learn = Learner(dls, vit_model, metrics=accuracy)\n",
    "\n",
    "# Train the model\n",
    "learn.fine_tune(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('./', f\"vit-3.pkl\")\n",
    "\n",
    "learn.export(path)\n",
    "# Plot the training an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import load_learner\n",
    "\n",
    "# Load the trained model\n",
    "path = './vit-2.pkl'\n",
    "learn = load_learner(path)\n",
    "\n",
    "# Load an image\n",
    "img_path = 'tshirt_20230920154938.png'\n",
    "img = Image.open(img_path)\n",
    "img = img.rotate(-275)\n",
    "# If you used any specific item transforms during training, apply them here\n",
    "img = img.resize((224, 224))  # Example resize, adjust according to your training setup\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "# Make a prediction\n",
    "pred, pred_idx, probs = learn.predict(img)\n",
    "\n",
    "print(f\"Prediction: {pred}\")\n",
    "print(f\"Prediction Index: {pred_idx}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
